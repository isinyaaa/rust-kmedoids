use crate::arrayadapter::ArrayAdapter;
use core::ops::{AddAssign, Div, Sub};
use num_traits::{Signed, Zero};
use std::convert::From;

/// Compute the Silhouette of a strict partitional clustering.
///
/// The Silhouette, proposed by Peter Rousseeuw in 1987, is a popular internal
/// evaluation measure for clusterings. Although it is defined on arbitary metrics,
/// it is most appropriate for evaluating "spherical" clusters, as it expects objects
/// to be closer to all members of its own cluster than to members of other clusters.
///
/// Because of the additional requirement of a division operator, this implementation
/// currently always returns a float result, and accepts only input distances that can be
/// converted into floats.
///
/// * type `M` - matrix data type such as `ndarray::Array2` or `kmedoids::arrayadapter::LowerTriangle`
/// * type `N` - number data type such as `u32` or `f64`
/// * type `L` - number data type such as `f64` for the cost (use a float type)
/// * `mat` - a pairwise distance matrix
/// * `assi` - the cluster assignment
/// * `samples` - whether to keep the individual samples, or not
///
/// returns a tuple containing:
/// * the average silhouette
/// * the individual silhouette values (empty if `samples = false`)
///
/// ## Panics
///
/// * panics when the dissimilarity matrix is not square
///
/// ## Example
/// Given a dissimilarity matrix of size 4 x 4, use:
/// ```
/// let data = ndarray::arr2(&[[0,1,2,3],[1,0,4,5],[2,4,0,6],[3,5,6,0]]);
/// let mut meds = kmedoids::random_initialization(4, 2, &mut rand::thread_rng());
/// let (loss, assi, n_iter): (f64, _, _) = kmedoids::alternating(&data, &mut meds, 100);
/// let (sil, _): (f64, _) = kmedoids::silhouette(&data, &assi, false);
/// println!("Silhouette is: {}", sil);
/// ```
pub fn silhouette<M, N, L>(mat: &M, assi: &[usize], samples: bool) -> (L, Vec<L>)
where
    N: Zero + PartialOrd + Clone,
    L: AddAssign
        + Div<Output = L>
        + Sub<Output = L>
        + Signed
        + Zero
        + PartialOrd
        + Clone
        + From<N>
        + From<u32>,
    M: ArrayAdapter<N>,
{
    assert!(mat.is_square(), "Dissimilarity matrix is not square");
    // NOTE: allocation?
    let mut sil = vec![L::zero(); if samples { assi.len() } else { 0 }];
    let mut lsum: L = L::zero();
    let mut buf = Vec::<(u32, L)>::new();
    for (i, &ai) in assi.iter().enumerate() {
        buf.clear();
        for (j, &aj) in assi.iter().enumerate() {
            while aj >= buf.len() {
                buf.push((0, L::zero()));
            }
            if i != j {
                buf[aj].0 += 1;
                buf[aj].1 += mat.get(i, j).into();
            }
        }
        if buf.len() == 1 {
            return (L::zero(), sil);
        }
        let s = if buf[ai].0 > 0 {
            let a = checked_div(buf[ai].1.clone(), buf[ai].0.into());
            let mut tmp = buf
                .iter()
                .enumerate()
                .filter(|&(i, _)| i != ai)
                .map(|(_, p)| checked_div(p.1.clone(), p.0.into()));
            // Ugly hack to get the min():
            let tmp2 = tmp.next().unwrap_or_else(L::zero);
            let b = tmp.fold(tmp2, |x, y| if y < x { y } else { x });
            checked_div(b.clone() - a.clone(), if a > b { a } else { b })
        } else {
            L::zero() // singleton
        };
        if samples {
            sil[i] = s.clone();
        }
        lsum += s.clone();
    }
    if samples {
        assert_eq!(sil.len(), assi.len(), "Length not as expected.");
    }
    (lsum.div((assi.len() as u32).into()), sil)
}

/// Compute the Medoid Silhouette of a clustering.
///
/// The Medoid Silhouette is an approximation to the original Silhouette where the
/// distance to the cluster medoid is used instead of the average distance, hence reducing
/// the run time from O(NÂ²) to O(Nk). Here we assume that every object is assigned the
/// nearest cluster, and hence only a distance matrix and a list of medoids is given.
///
/// Because of the additional requirement of a division operator, this implementation
/// currently always returns a float result, and accepts only input distances that can be
/// converted into floats.
///
/// TODO: allow using N x k distance matrixes, too.
///
/// * type `M` - matrix data type such as `ndarray::Array2` or `kmedoids::arrayadapter::LowerTriangle`
/// * type `N` - number data type such as `u32` or `f64`
/// * type `L` - number data type such as `f64` for the cost (use a float type)
/// * `mat` - a pairwise distance matrix
/// * `meds` - the medoid list
/// * `samples` - whether to keep the individual samples, or not
///
/// returns a tuple containing:
/// * the average medoid silhouette
/// * the individual medoid silhouette values (empty if `samples = false`)
///
/// ## Panics
///
/// * panics when the dissimilarity matrix is not square
///
/// ## Example
/// Given a dissimilarity matrix of size 4 x 4, use:
/// ```
/// let data = ndarray::arr2(&[[0,1,2,3],[1,0,4,5],[2,4,0,6],[3,5,6,0]]);
/// let mut meds = kmedoids::random_initialization(4, 2, &mut rand::thread_rng());
/// let (loss, assi, n_iter): (f64, _, _) = kmedoids::alternating(&data, &mut meds, 100);
/// let (sil, _): (f64, _) = kmedoids::medoid_silhouette(&data, &meds, false);
/// println!("Silhouette is: {}", sil);
/// ```
pub fn medoid_silhouette<M, N, L>(mat: &M, meds: &[usize], samples: bool) -> (L, Vec<L>)
where
    N: Zero + PartialOrd + Clone,
    L: AddAssign
        + Div<Output = L>
        + Sub<Output = L>
        + Signed
        + Zero
        + PartialOrd
        + Clone
        + From<N>
        + From<u32>,
    M: ArrayAdapter<N>,
{
    let (n, k) = (mat.len(), meds.len());
    assert!(mat.is_square(), "Dissimilarity matrix is not square");
    assert!(n <= u32::MAX as usize, "N is too large");
    // NOTE: allocation?
    let mut sil = vec![L::one(); if samples { n } else { 0 }];
    if k == 1 {
        return (L::one(), sil);
    } // not really well-defined
    assert!(k <= n, "invalid k, must be over 1 and at most N");
    let mut loss = L::zero();
    #[allow(clippy::needless_range_loop)]
    for i in 0..n {
        let (d1, d2) = (mat.get(i, meds[0]), mat.get(i, meds[1]));
        let mut best = if d1 < d2 { (d1, d2) } else { (d2, d1) };
        for &m in meds.iter().skip(2) {
            let d = mat.get(i, m);
            if d < best.0 {
                best = (d, best.0);
            } else if d < best.1 {
                best = (best.0, d);
            }
        }
        if !N::is_zero(&best.0) {
            let s = <L as From<N>>::from(best.0.clone()) / <L as From<N>>::from(best.1.clone());
            if samples {
                sil[i] = L::one() - s.clone();
            }
            loss += s;
        }
    }
    loss = L::one() - loss / <L as From<u32>>::from(n as u32);
    (loss, sil)
}

// helper function, returns 0 on division by 0
pub(crate) fn checked_div<L>(x: L, y: L) -> L
where
    L: Div<Output = L> + Zero + Clone + PartialOrd,
{
    if y > L::zero() {
        x.div(y)
    } else {
        L::zero()
    }
}
